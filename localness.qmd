---
title: "SERP: Localness and domains ranking"
author: "Liolia Bajemon"
format: html
editor: visual
---

### Description

The aim of this document is to answer the following questions:

-   Where does the data collected from the SERP come from?

-   Which countries produce the most data?

-   Is the data produced locally?

-   Are there domains or websites which predominate the web?

We will try to answer these questions by 1. comparing the language of the website to the local language (of the country) and 2. comparing the domain of the website to the country's top-level domain.

### Set-up

```{r set_up, message = FALSE, warning = FALSE}
library(urltools)
library(RColorBrewer)
library(tidyverse)
library(polyglotr)
library(scales)
library(Rwhois)
library(ggplot2)
library(maps)
library(ggalt)
library(proj4)
library(sf)
library(rnaturalearth)
```

### Read data

```{r read_data}
data_city_river = read.csv("input_data/data_city_river.csv") %>% 
  select(c("fid", "latitude", "longitude", "hl1", "hl2", "hl3", "hl4", "hl5", "hl6", "ville", "riviere"))
# rename the "domain" column 
languages_code = read.csv("input_data/languages_code.csv", sep = ";") # iso code for each language
domain_code = read.csv("input_data/country_code_internet.csv", sep = ",") %>% # internet domain for each country
  select(c("gl", "tld"))
data_combined = read.csv("collected_data/hl/df_scrap_tokens_all_hl.csv") %>% # this dataframe combines all the collected data for local languages queries
  left_join(data_city_river, by = "fid") %>% 
  # Add country domain
  left_join(domain_code, by = "gl") %>% 
  # rename the "domain" column to avoid confusions 
  dplyr::rename(full_domain = domain) %>% 
  mutate(hl = str_replace_all(hl, "zh-cn", "zh-CN")) %>% 
  mutate(hl1 = str_replace_all(hl1, "zh-cn", "zh-CN")) %>% 
  mutate(hl2 = str_replace_all(hl2, "zh-cn", "zh-CN")) 
```

### Get localness score

```{r detect_language}
language1 = function(text, snippet, title, hl){
  print(title)
   if(!is.na(text)){
     short_text = substr(text, 1, 500)
     res = language_detect(short_text)
     if(res == hl){
       return(TRUE)
     } else {
       return(FALSE)
     }
   }
     # if there is no text, check if there is a snippet
   else {
       if(!is.na(snippet)){
         res = language_detect(snippet)
         if(res == hl){
           return(TRUE)
         } else {
           return(FALSE)
         }
       } else {
         if(!is.na(title)){
           res = language_detect(title)
           if(res == hl){
             return(TRUE)
             } else {
               return(FALSE)
               }
           }
     }
   }
}
```

```{r detect_all_languages}
detect_all_lang = function(text, snippet, title, hl1, hl2, hl3, hl4, hl5, hl6, full_domain){
  if(!is.na(text) & (full_domain != "www.youtube.com") & text != "" & (full_domain != "www.facebook.com")){
     short_text = substr(text, 1, 500)
     res = language_detect(short_text)
     if(res %in% c(hl1, hl2, hl3, hl4, hl5, hl6)){
       return(TRUE)
     } else {
       return(FALSE)
     }
   }
     # if there is no text, check if there is a snippet
   else {
       if(!is.na(snippet)){
         res = language_detect(snippet)
         if(res %in% c(hl1, hl2, hl3, hl4, hl5, hl6)){
           return(TRUE)
         } else {
           return(FALSE)
         }
       } else {
         if(!is.na(title)){
           res = language_detect(title)
           if(res %in% c(hl1, hl2, hl3, hl4, hl5, hl6)){
             return(TRUE)
             } else {
               return(FALSE)
             }
           }
         }
   }
}
```

```{r detect_tld}
detect_tld = function(gl, tld, suffix1, suffix2, subdomain){
if (gl != "us") {
    if ((!is.na(suffix1) && suffix1 == tld) || 
        (!is.na(suffix2) && suffix2 == tld) || 
        (!is.na(subdomain) && subdomain == tld)) {
        return(TRUE)
    } else {
        return(FALSE)
    }
} else {
    tld_list <- unlist(strsplit(tld, " "))
    if ((!is.na(suffix1) && suffix1 %in% tld_list) || 
        (!is.na(suffix2) && suffix2 %in% tld_list) || 
        (!is.na(subdomain) && subdomain %in% tld_list)) {
        return(TRUE)
    } else {
        return(FALSE)
    }
}
}
```

```{r localness_calc}

localness_city = function(fid_city){
  
  print(fid_city)
  
  if(!file.exists(glue::glue("analysis/localness/localness_{fid_city}.csv"))){
  df_fid = data_combined %>% 
    filter(fid == fid_city)
    
  df = df_fid %>% 
      # extract the suffix from the full domain with the urltools package
      dplyr::mutate(suffix = (suffix_extract(df_fid$full_domain))$suffix) %>% 
      # extract the subdomain
      mutate(subdomain = (suffix_extract(domain(df_fid$full_domain)))$subdomain) %>% 
      # extract the domain
      mutate(domain = (suffix_extract(domain(df_fid$full_domain)))$domain) %>%   # separate the suffix if necessary
      separate(suffix, c("suffix1", "suffix2"), sep = "\\.", remove = FALSE)
    
    locals = df %>% 
      # now check if the suffix or the subdomain corresponds to the suffix of the country
      rowwise() %>%
      mutate(local_tld = detect_tld(gl, tld, suffix1, suffix2, subdomain)) %>% 
      mutate(search_lang = language1(text, snippet, title, hl)) %>% 
      mutate(local_lang = detect_all_lang(text, snippet, title, hl1, hl2, hl3, hl4, hl5, hl6, full_domain)) %>% 
      ungroup()
    
    print("fichier OK")
    
    write.csv(locals, glue::glue("analysis/localness/localness_{fid_city}.csv"), row.names = FALSE)
  }
}
```

```{r run_localness}
data_china = read.csv("input_data/data_city_river.csv") %>% 
  filter(gl == "cn")
data_china %>% 
  mutate(fid_city = fid) %>%                                  
  mutate(data = purrr::map(fid_city, localness_city))
```

```{r}
# format data
localness_format = function(fid){
  data = read.csv(paste0("analysis/localness/localness_city/localness_", fid, ".csv")) %>% 
    select(c("urban_aggl", "riviere", "ville", "local_tld","search_lang", "local_lang"))
  
  write.csv(data, paste0("analysis/localness/localness_compile/localness_", fid, ".csv"))
}

data_city_river %>% 
  mutate(fid_city = fid) %>%                                  
  mutate(data = purrr::map(fid_city, localness_format))

# compile everything
df =  read.csv("input_data/data_city_river.csv") %>%
  select(c("fid")) %>% 
  mutate(path = paste0("analysis/localness/localness_compile/localness_", fid, ".csv"))  %>% 
  mutate(data = purrr::map(path, read.csv)) %>% 
  unnest(data)
write.csv(df, "analysis/localness/localness_compile.csv")

df_cat = df %>% 
  group_by(fid, local_tld, local_lang) %>% 
  summarise(nb = n())

df2 = read.csv("input_data/data_city_river.csv") %>%
  select(c("fid", "ville", "riviere")) %>%
  left_join(df_cat, by = "fid")

write.csv(df2, "analysis/localness/df_matrix.csv")
```

### Global maps

We will make three maps:

1.  Percentage of pages for which the top-level domain is local

2.  Percentage of pages for which the language of the website is a local one.

3.  Percentage of pages for which the language is the one of the sent query.

    ```{r}
    world_map = ne_countries(scale = "medium", returnclass = "sf")
    ```

#### Local domain

```{r local_domain}

# get localness scores
df = read.csv("analysis/localness/localness_compile.csv") %>% 
  group_by(fid, local_tld) %>% 
  mutate(nb = n()) %>% 
  ungroup() %>% 
  group_by(fid) %>% 
  mutate(total_fid = n()) %>% 
  mutate(perc = nb/total_fid*100) %>% 
  filter(local_tld == TRUE) %>% 
  select(c("fid", "perc")) %>% 
  distinct()

data_city_river = read.csv("input_data/data_city_river.csv") %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  left_join(df, by = "fid") %>% 
  mutate(perc = replace_na(perc, 0))

# map 
data_sf <- st_as_sf(data_city_river, coords = c("longitude", "latitude"), crs = 4326)
world_map %>% 
  ggplot() +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(color = perc), size = 3) +
  # color palette
  scale_color_gradientn(colors = c(brewer.pal(n = 9, name = "Spectral"))) +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom") +
  # legend
  labs(color = "Adresses web locales (%)")  

ggsave("analysis/localness/carte_localness_adresse.png", width = 4000, height = 2500, units = "px")
ggsave("analysis/localness/carte_localness_adresse.svg", width = 4000, height = 2500, units = "px")
```

#### Local language

```{r score_local2}
# get localness scores
df = read.csv("analysis/localness/localness_compile.csv") %>% 
  group_by(fid, local_lang) %>% 
  mutate(nb = n()) %>% 
  ungroup() %>% 
  group_by(fid) %>% 
  mutate(total_fid = n()) %>% 
  mutate(perc = nb/total_fid*100) %>% 
  filter(local_lang == TRUE) %>% 
  select(c("fid", "perc")) %>% 
  distinct()

data_city_river = read.csv("input_data/data_city_river.csv") %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  left_join(df, by = "fid") %>% 
  mutate(perc = replace_na(perc, 0))

# map 
data_sf <- st_as_sf(data_city_river, coords = c("longitude", "latitude"), crs = 4326)
world_map %>% 
  ggplot() +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(color = perc), size = 3) +
  # color palette
  scale_color_gradientn(colors = c(brewer.pal(n = 9, name = "Spectral"))) +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom") +
  # legend
  labs(color = "Langues locales (%)")  

ggsave("analysis/localness/carte_localness_langue_locale.png", width = 4000, height = 2500, units = "px")
ggsave("analysis/localness/carte_localness_langue_locale.svg", width = 4000, height = 2500, units = "px")
```

#### Request language

```{r}
# get localness scores
df = read.csv("analysis/localness/localness_compile.csv") %>% 
  group_by(fid, search_lang) %>% 
  mutate(nb = n()) %>% 
  ungroup() %>% 
  group_by(fid) %>% 
  mutate(total_fid = n()) %>% 
  mutate(perc = nb/total_fid*100) %>% 
  filter(search_lang == TRUE) %>% 
  select(c("fid", "perc")) %>% 
  distinct()

data_city_river = read.csv("input_data/data_city_river.csv") %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  left_join(df, by = "fid") %>% 
  mutate(perc = replace_na(perc, 0))

# map 
data_sf <- st_as_sf(data_city_river, coords = c("longitude", "latitude"), crs = 4326)
world_map %>% 
  ggplot() +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(color = perc), size = 3) +
  # color palette
  scale_color_gradientn(colors = c(brewer.pal(n = 9, name = "Spectral"))) +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom") +
  # legend
  labs(color = "Résultats dans la langue de requête (%)")  

ggsave("analysis/localness/carte_localness_requete.png", width = 4000, height = 2500, units = "px")
ggsave("analysis/localness/carte_localness_requete.svg", width = 4000, height = 2500, units = "px")
```

### Matrix

#### For each city

Let's plot a matrix for each city.

```{r def_matrix_plot}
matrix_plot = function(fid_city){
  
  df = df_cat %>% 
    filter(fid == fid_city) %>% 
    mutate(cat = case_when(
      local_tld == TRUE & local_lang == TRUE ~ "B",
      local_tld == TRUE & local_lang == FALSE ~ "D",
      local_tld == FALSE & local_lang == FALSE ~ "C",
      local_tld == FALSE & local_lang == TRUE ~ "A"
      )) %>% 
    mutate(tld_local = case_when(
      local_tld == FALSE ~ "NON",
      local_tld == TRUE ~ "OUI"
    )) %>% 
    mutate(lang_local = case_when(
      local_lang == FALSE ~ "NON",
      local_lang == TRUE ~ "OUI"
    ))
  
  ggplot(df, aes(lang_local, tld_local)) +
    geom_point(aes(color = cat, size = nb)) +
    geom_text(aes(label = nb), color = "black", size = 4) +
    coord_fixed() +
    scale_color_manual(values = c("A" = "#F474C9", "B" = "#CE6B6A","C" = "#E8E8E8", "D" = "#9CD52A"))  + 
    theme_bw()+
    theme(legend.position = "none")+
    scale_size(range = c(5, 30)) + 
    labs(x = "Langue locale",
         y = "Adresse web locale",
         title = paste0(df$ville, " et ", df$riviere))
  
  ggsave(paste0("analysis/localness/localness_matrix/matrix_", fid_city, ".png"), width = 10, height = 10, units = "cm")
}
```

```{r run_matrix_plot}
# run the function

df_cat = read.csv("analysis/localness/df_matrix.csv")
data_city_river = read.csv("input_data/data_city_river.csv")

data_china %>% 
  mutate(fid_city = fid) %>%                                  
  mutate(data = purrr::map(fid_city, matrix_plot))
```

#### For the entire corpus

Now let's plot a matrix for the entire corpus:

```{r global_matrix}

# Define dataset
df_global = read.csv("analysis/localness/localness_compile.csv") %>% 
  group_by(local_tld, local_lang) %>% 
  summarise(nb = n()) %>% 
  mutate(tld_local = case_when(
    local_tld == FALSE ~ "NON",
    local_tld == TRUE ~ "OUI"
    )) %>% 
  mutate(lang_local = case_when(
    local_lang == FALSE ~ "NON",
    local_lang == TRUE ~ "OUI"
    )) %>% 
  mutate(cat = case_when(
    local_tld == TRUE & local_lang == TRUE ~ "B",
    local_tld == TRUE & local_lang == FALSE ~ "D",
    local_tld == FALSE & local_lang == FALSE ~ "C",
    local_tld == FALSE & local_lang == TRUE ~ "A"
    )) 

# Plot
ggplot(df_global, aes(lang_local, tld_local)) +
  geom_point(aes(color = cat, size = nb)) +
  geom_text(aes(label = nb), color = "black", size = 4) +
  coord_fixed() +
  scale_color_manual(values = c("A" = "#F474C9", "B" = "#CE6B6A","C" = "#E8E8E8", "D" = "#9CD52A"))  + 
  theme_bw() +
  theme(legend.position = "none") +
  scale_size(range = c(5, 50)) + 
  labs(x = "Langue locale",
       y = "Adresse web locale")
  
ggsave("analysis/localness/matrix_corpus.png", width = 10, height = 10, units = "cm")
```
