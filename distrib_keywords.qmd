---
title: "Keywords global distribution"
format: html
editor: visual
author: "Liolia Bajemon"
---

### Description

This document aims at representing on a map the distribution of a given keyword in our corpus (see <https://github.com/lbajemon/glourb_serp/blob/main/compilation.qmd>). For example, riverfronts and waterfronts are mentioned in almost 200 cities. The idea is to plot the number of mentions of this keyword in each city. For example, it is mentioned in 91 pages in Ahmedabad (India).

### Set up

```{r packages}
library(tidyverse)
library(rnaturalearth) # world map
library(sf) # map
library(cowplot) # arrange plots together
library(leaflet) # leaflet map
library(htmltools) # title on leaflet map
library(htmlwidgets) # to save leaflet map

tag.map.title = tags$style(HTML("
  .leaflet-control.map-title { 
    transform: translate(-50%,20%);
    position: topright;
    left: 50%;
    text-align: center;
    padding-left: 10px; 
    padding-right: 10px; 
    background: rgba(50, 111, 168,0.5);
    #font-weight: bold;
    font-size: 18px;
    color: white;
  }
"))
```

```{r read_corpus}
corpus = read.csv("collected_data/corpus_distinct.csv") 
data_city_river = read.csv("input_data/data_city_river_303.csv") 
fid_fusion = read.csv("input_data/data_city_river_fid_fusion.csv") %>% 
  select(c("fid","fid_fusion"))
```

### Major keywords

We have selected four thematics which seem important but do not necessarily appear as thematic worlds in our corpus: riverfronts and waterfronts, climate change and global warming, water scarcity/shortage, and sand/gravel mining/extraction.

#### Riverfront

```{r riverfront_data}
riverfronts = corpus %>% 
  # keep pages mentioning a waterfront or riverfront
  filter(str_detect(text_en, "riverfront|waterfront")) %>% # 980 pages 
  # do not keep the exact same page twice
  distinct(link, .keep_all = TRUE) %>% # 811 pages
  group_by(urban_aggl) %>% 
  # count nb of occurrences per city
  count() 

# 182 cities mention a water/riverfront
# prepare dataset for representing it on a map
data = corpus %>% 
  select(c("urban_aggl", "latitude", "longitude")) %>% 
  distinct(urban_aggl, .keep_all = TRUE) %>% 
  left_join(riverfronts, by = "urban_aggl") %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  # remove cities which do not mention the river/waterfront
  filter(!is.na(n))

quantile(riverfronts$n)

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n), color = "#41b6c4", alpha = 0.7, show.legend = TRUE) +
  scale_size_continuous(breaks = c(1, 3, 6, 88)) +
  # color palette
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white")) +
  # legend
  labs(size = "Nombre de pages mentionnant un front d'eau")   
ggsave("analysis/keywords/map_riverfront.svg", width = 4000, height = 2500, units = "px")

### DIAGRAM
data %>% 
  mutate(urban_aggl = fct_reorder(urban_aggl, n)) %>% 
  filter(n >= 12) %>% 
  ggplot(mapping = aes(x = urban_aggl, # create the plot
                      y = n)) + 
    geom_col(fill = "#41b6c4", position = "stack") +
    coord_flip() + # flip x and y coordinates 
    labs(x = "",
         y = "") + 
    theme_bw(base_family = "CenturySch")
ggsave("analysis/keywords/diagram_riverfront.png", width = 750, height = 950, units = "px")

### LEAFLET MAP (Interactive)
title = tags$div(
  tag.map.title, HTML("<td align=justify><b>Nombre de mentions de 'riverfront' ou de 'waterfront'</b></td>"))
leaf = leaflet(data = data, options = leafletOptions(zoomControl = TRUE, minZoom = 1, maxZoom = 5)) %>% 
  addProviderTiles("CartoDB.VoyagerNoLabels") %>% 
  addCircleMarkers(~longitude, 
                   ~latitude,
                   label = paste0(data$urban_aggl,", ", data$n),
                   color = "#41b6c4",
                   opacity = 1,
                   radius = 0.2*data$n) %>% 
  addControl(title, position = "topright") 
saveWidget(leaf, file = "occurrence_riverfront_leaflet.html")
```

#### Water scarcity

```{r data_water_scarcity}
water_scarcity = corpus %>% 
  filter(str_detect(text_en, "water scarcity|water shortage|drought")) %>% 
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count() 

# prepare dataset for representing it on a map
data = data_city_river %>% 
  select(c("fid", "nom", "latitude", "longitude")) %>% 
  left_join(water_scarcity, by = join_by("fid" == "fid_fusion")) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  filter(!is.na(n))

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n), color = "#fdb462", alpha = 0.7, show.legend = TRUE) +
 # scale_size_area(breaks = c(1, 5, 10, 20, 44)) +
  # color palette
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white"),
        legend.text = element_text(size = 15),
        legend.title = element_text(size = 15)) +
  # legend
  labs(size = "Nombre de pages mentionnant une sÃ©cheresse")   
ggsave("analysis/keywords/map_scarcity.svg", width = 4000, height = 2500, units = "px")

### DIAGRAM
data %>% 
  mutate(nom = fct_reorder(nom, n)) %>% 
  filter(n > 14) %>% 
  ggplot(mapping = aes(x = nom, # create the plot
                      y = n)) + 
    geom_col(fill = "#fdb462", position = "stack") +
    coord_flip() + # flip x and y coordinates 
    labs(x = "",
         y = "") + 
    theme_bw(base_family = "CenturySch") +
  theme(axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15))
  
ggsave("analysis/keywords/diagram_scarcity.png", width = 850, height = 950, units = "px")
ggsave("analysis/keywords/diagram_scarcity.svg", width = 2000, height = 1000, units = "px")

### LEAFLET MAP (Interactive)
title = tags$div(
  tag.map.title, HTML("<td align=justify><b>Nombre de mentions de 'water scarcity' ou de 'water shortage'</b></td>"))
leaf = leaflet(data = data, options = leafletOptions(zoomControl = TRUE, minZoom = 1, maxZoom = 5)) %>% 
  addProviderTiles("CartoDB.VoyagerNoLabels") %>% 
  addCircleMarkers(~longitude, 
                   ~latitude,
                   label = paste0(data$urban_aggl,", ", data$n),
                   color = "#fdb462",
                   opacity = 1,
                   radius = 0.5*data$n) %>% 
  addControl(title, position = "topright") 
saveWidget(leaf, file = "occurrence_water_scarcity_leaflet.html")
```

#### Climate change

```{r climate_change}
climate_change = corpus %>% 
  # keep pages mentioning climate change, global warming
  filter(str_detect(text_en, "climate change|global warming")) %>% 
  # do not keep the exact same page twice
  distinct(link, .keep_all = TRUE) %>% # 811 pages
  group_by(urban_aggl) %>% 
  # count nb of occurrences per city
  count() 

# 245 cities

# prepare dataset for representing it on a map
data = corpus %>% 
  select(c("urban_aggl", "latitude", "longitude")) %>% 
  distinct(urban_aggl, .keep_all = TRUE) %>% 
  left_join(climate_change, by = "urban_aggl") %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  # remove cities which do not mention the keyword
  filter(!is.na(n))

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

map = ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n), color = "#fc8d62", alpha = 0.7, show.legend = TRUE) +
  scale_size_area(max_size = 5)  +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white")) +
  # legend
  labs(size = "Nombre de mentions de 'climate change' ou de 'global warming'")


### DIAGRAM
diagram = data %>% 
  mutate(urban_aggl = fct_reorder(urban_aggl, n)) %>% 
  filter(n >= 9) %>% 
  ggplot(mapping = aes(x = urban_aggl, # create the plot
                      y = n)) + 
    geom_col(fill = "#fc8d62", position = "stack") +
    coord_flip() + # flip x and y coordinates 
    labs(x = "",
         y = "") + 
    theme_bw(base_family = "CenturySch")

### JOIN EVERYTHING AND SAVE
plot_grid(map, diagram, rel_widths = c(2,1))
ggsave("occurrence_climate_change.png", path = "analysis/keywords/", width = 4000, height = 2500, units = "px")

### LEAFLET MAP (Interactive)
title = tags$div(
  tag.map.title, HTML("<td align=justify><b>Nombre de mentions de 'climate change' ou de 'global warming'</b></td>"))
leaf = leaflet(data = data, options = leafletOptions(zoomControl = TRUE, minZoom = 1, maxZoom = 5)) %>% 
  addProviderTiles("CartoDB.VoyagerNoLabels") %>% 
  addCircleMarkers(~longitude, 
                   ~latitude,
                   label = paste0(data$urban_aggl,", ", data$n),
                   color = "#fc8d62",
                   opacity = 1,
                   radius = 0.5*data$n) %>% 
  addControl(title, position = "topright") 
saveWidget(leaf, file = "occurrence_climate_change_leaflet.html")
```

#### Gravel mining

```{r gravel_mining}
gravel_mining = corpus %>% 
  # keep pages mentioning sand or gravel mining or extraction
  filter(str_detect(text_en, "sand mining|gravel mining|sand extraction|gravel extraction")) %>% 
  # do not keep the exact same page twice
  distinct(link, .keep_all = TRUE) %>% # 88 pages
  group_by(urban_aggl) %>% 
  # count nb of occurrences per city
  count() 

# prepare dataset for representing it on a map
data = corpus %>% 
  select(c("urban_aggl", "latitude", "longitude")) %>% 
  distinct(urban_aggl, .keep_all = TRUE) %>% 
  left_join(gravel_mining, by = "urban_aggl") %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  # remove cities which do not mention the keyword
  filter(!is.na(n))

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

map = ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n), color = "#7fcdbb", alpha = 0.7, show.legend = TRUE) +
  scale_size_area(breaks = c(2, 4, 5, 10, 13), max_size = 5)  +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white")) +
  # legend
  labs(size = "Nombre de mentions de 'sand/gravel mining/extraction'")


### DIAGRAM
diagram = data %>% 
  mutate(urban_aggl = fct_reorder(urban_aggl, n)) %>% 
  filter(n >= 2) %>% 
  ggplot(mapping = aes(x = urban_aggl, # create the plot
                      y = n)) + 
    geom_col(fill = "#7fcdbb", position = "stack") +
    coord_flip() + # flip x and y coordinates 
    labs(x = "",
         y = "") + 
    theme_bw(base_family = "CenturySch")

### JOIN EVERYTHING AND SAVE
plot_grid(map, diagram, rel_widths = c(2,1))
ggsave("occurrence_gravel_mining.png", path = "analysis/keywords/", width = 4000, height = 2500, units = "px")

### LEAFLET MAP (Interactive)
title = tags$div(
  tag.map.title, HTML("<td align=justify><b>Nombre de mentions de 'sand/gravel mining/extraction'</b></td>"))
leaf = leaflet(data = data, options = leafletOptions(zoomControl = TRUE, minZoom = 1, maxZoom = 5)) %>% 
  addProviderTiles("CartoDB.VoyagerNoLabels") %>% 
  addCircleMarkers(~longitude, 
                   ~latitude,
                   label = paste0(data$urban_aggl,", ", data$n),
                   color = "#7fcdbb",
                   opacity = 1,
                   radius = 0.5*data$n) %>% 
  addControl(title, position = "topright") 
saveWidget(leaf, file = "occurrence_gravel_mining_leaflet.html")
```

### Define general function

Now let's make a general function which produces a map and a diagram based on a given keyword.

```{r def_keyword_map}
keyword_map = function(motCle, maCouleur, monTitre, nomFichier){

  # Get dataframe
  df_keyword = corpus %>% 
    # keep pages mentioning the keyword
    filter(str_detect(text_en, motCle)) %>% 
    # do not keep the exact same page twice
    distinct(link, .keep_all = TRUE) %>%
    group_by(urban_aggl) %>% 
    # count nb of occurrences per city
    count()
 
  data = corpus %>% 
    select(c("urban_aggl", "latitude", "longitude")) %>% 
    distinct(urban_aggl, .keep_all = TRUE) %>% 
    left_join(df_keyword, by = "urban_aggl") %>% 
    mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
    mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
    # remove cities which do not mention the keyword
    filter(!is.na(n))
  
  ### Make an interactive map
  max_n = max(data$n)
  rad = if(max_n<100){0.5} else {0.2}
  n_cities = nrow(data)
  title = tags$div(
    tag.map.title, HTML(paste0("<td align=justify><b>Nombre de mentions de '", monTitre, "'</b><br>", n_cities, " villes</td>")))
  leaf = leaflet(data = data, options = leafletOptions(zoomControl = TRUE, minZoom = 1, maxZoom = 5)) %>% 
    addProviderTiles("CartoDB.VoyagerNoLabels") %>% 
    addCircleMarkers(~longitude, 
                     ~latitude,
                     label = paste0(data$urban_aggl,", ", data$n),
                     color = maCouleur,
                     opacity = 1,
                     radius = rad*data$n) %>% 
    addControl(title, position = "topright") 
  
  saveWidget(leaf, file = paste0("occurrence_leaflet_", nomFichier, ".html"), selfcontained = TRUE)
}
```

### Floods

```{r}
data_city_river = read.csv("input_data/data_city_river_303.csv") 
fid_fusion = read.csv("input_data/data_city_river_fid_fusion.csv") %>% 
  select(c("fid","fid_fusion"))

df = corpus %>% 
  dplyr::rename(tokenized = tokenized_noloc) %>% 
  subset(!is.na(tokenized)) %>% 
  filter(str_detect(tokenized, "flood|flooding|inundation")) %>%  
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count() 

data = data_city_river %>% 
  select(c("fid", "urban_aggl", "latitude", "longitude")) %>% 
  left_join(df, by = join_by("fid" == "fid_fusion")) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  filter(!is.na(n))

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, color = "#41b6c4", aes(size = n), alpha = 0.8, show.legend = TRUE) +
  scale_size_area(breaks = c(1, 11, 19, 33, 176)) +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white"),
        legend.text = element_text(size = 15),
        legend.title = element_text(size = 15)) +
  # legend
  labs(size = "Nombre de pages mentionnant une inondation")   
ggsave("analysis/keywords/map_floods.svg", width = 4000, height = 2500, units = "px")
```

### Dams

```{r}
data_city_river = read.csv("input_data/data_city_river_303.csv") 
fid_fusion = read.csv("input_data/data_city_river_fid_fusion.csv") %>% 
  select(c("fid","fid_fusion"))

df = corpus %>% 
  dplyr::rename(tokenized = tokenized_noloc) %>% 
  subset(!is.na(tokenized)) %>% 
  filter(str_detect(tokenized, " dam |barrage|weir")) %>%  
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count() 

data = data_city_river %>% 
  select(c("fid", "urban_aggl", "latitude", "longitude")) %>% 
  left_join(df, by = join_by("fid" == "fid_fusion")) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  filter(!is.na(n)) 

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n), color = "#bebada", alpha = 0.8, show.legend = TRUE) +
  scale_size_area(breaks = c(1, 6, 12, 24, 141)) +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white"),
        legend.text = element_text(size = 15),
        legend.title = element_text(size = 15)) +
  # legend
  labs(size = "Nombre de pages mentionnant un barrage")   
ggsave("analysis/keywords/map_dams.svg", width = 4000, height = 2500, units = "px")
```

### Pollution

```{r}
pollution = corpus %>% 
  filter(str_detect(tokenized_text, "acidification|phosphorus|organic matter|nitrate|microbe|micro-organism|microorganism|phosphate|pollutant|coliform|pollution|pollute|contamination")) %>%
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count()

data = data_city_river %>% 
  select(c("fid", "nom", "latitude", "longitude")) %>% 
  left_join(pollution, by = join_by("fid" == "fid_fusion")) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  filter(!is.na(n)) 

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n), color = "#fb9a99", alpha = 0.8, show.legend = TRUE) +
  scale_size_area(breaks = c(1, 5, 10, 17, 90)) +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white"),
        legend.text = element_text(size = 15),
        legend.title = element_text(size = 15)) +
  # legend
  labs(size = "Nombre de pages parlant de pollution")   
ggsave("analysis/keywords/map_pollution.svg", width = 4000, height = 2500, units = "px")

data %>% 
  mutate(nom = fct_reorder(nom, n)) %>% 
  filter(n >= 40) %>% 
  ggplot(mapping = aes(x = nom, # create the plot
                      y = n)) + 
    geom_col(fill = "#fb9a99", position = "stack") +
    coord_flip() + # flip x and y coordinates 
    labs(x = "",
         y = "") +  
  theme_bw(base_family = "CenturySch") +
  theme(axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15))
ggsave("analysis/keywords/diagram_pollution.svg", width = 1500, height = 1500, units = "px")
```

### CroisiÃ¨res

```{r}
loisirs = corpus %>% 
  filter(str_detect(tokenized_text, "cruise")) %>%
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count()

data = data_city_river %>% 
  select(c("fid", "nom", "latitude", "longitude")) %>% 
  left_join(loisirs, by = join_by("fid" == "fid_fusion")) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  filter(!is.na(n)) 

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n), color = "#c51b8a", alpha = 0.8, show.legend = TRUE) +
  scale_size_area(breaks = c(1, 3, 10, 80)) +
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white"),
        legend.text = element_text(size = 15),
        legend.title = element_text(size = 15)) +
  # legend
  labs(size = "Nombre de pages parlant de croisiÃ¨res")   
ggsave("analysis/keywords/map_croisiere.svg", width = 4000, height = 2500, units = "px")

data %>% 
  mutate(nom = fct_reorder(nom, n)) %>% 
  filter(n >= 32) %>% 
  ggplot(mapping = aes(x = nom, # create the plot
                      y = n)) + 
    geom_col(fill = "#c51b8a", position = "stack") +
    coord_flip() + # flip x and y coordinates 
    labs(x = "",
         y = "") +  
  theme_bw(base_family = "CenturySch") +
  theme(axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15))
ggsave("analysis/keywords/diagram_croisiere.svg", width = 1500, height = 1500, units = "px")
```

### Riverfronts

```{r}

fronts_eau = corpus %>% 
  filter(str_detect(text_en, "riverfront|waterfront")) %>%
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count() %>% 
  rename("n_tot" = "n")

riverfronts = corpus %>% 
  filter(str_detect(text_en, "riverfront")) %>%
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count() %>% 
  rename("n_river" = "n")

waterfronts = corpus %>% 
  filter(str_detect(text_en, "waterfront")) %>%
  distinct(link, .keep_all = TRUE) %>% 
  left_join(fid_fusion, by = "fid") %>% 
  group_by(fid_fusion) %>% 
  count() %>% 
  rename("n_water" = "n")

# prepare dataset for representing it on a map
data = data_city_river %>% 
  select(c("fid", "nom", "latitude", "longitude")) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  left_join(riverfronts, by = join_by("fid" == "fid_fusion")) %>% 
  left_join(waterfronts, by = join_by("fid" == "fid_fusion")) %>% 
  left_join(fronts_eau, by = join_by("fid" == "fid_fusion")) %>% 
  mutate(latitude = as.numeric(str_replace_all(latitude, ",", "."))) %>% 
  mutate(longitude = as.numeric(str_replace_all(longitude, ",", "."))) %>% 
  filter(!is.na(n_water)|!is.na(n_river)) %>% 
  mutate(type = case_when(
    n_water < n_river ~ "Riverfront",
    n_water > n_river ~ "Waterfront",
    n_water == n_river ~ "Les deux",
    !is.na(n_water) & is.na(n_river) ~ "Waterfront",
    is.na(n_water) & !is.na(n_river) ~ "Riverfront"
    ))

quantile(data$n_tot)

### MAP
# Prepare data
data_sf = st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)
world_map = ne_countries(scale = "medium", returnclass = "sf")

ggplot(world_map) +
  # world map 
  geom_sf(fill = "#f0f0f1", color = "white", size = 0.2) +
  # city points
  geom_sf(data = data_sf, aes(size = n_tot, color = type), alpha = 0.7, show.legend = TRUE) +
  scale_size_continuous(breaks = c(1, 3, 6, 88)) +
  scale_color_manual(breaks = c("Riverfront", "Waterfront", "Les deux"),
                     values = c("#386cb0", "#66c2a5", "#a6d854")) +
  # color palette
  # equal earth projection
  coord_sf(crs = "+proj=eqearth") +
  # theme
  theme_void() +
  theme(legend.position = "bottom",
        plot.background = element_rect(fill = "white", color = "white")) +
  # legend
  labs(size = "Nombre de pages mentionnant un front d'eau",
       color = "Waterfront ou riverfront ?")   
ggsave("analysis/keywords/map_riverfront.svg", width = 4000, height = 2500, units = "px")
```
