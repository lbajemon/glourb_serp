---
title: "Search Engine Pages Results: Specificity scores calculation"
author: "Liolia Bajemon"
format: html
editor: visual
---

## Description

Thanks to the ![](https://dka575ofm4ao0.cloudfront.net/pages-transactional_logos/retina/211386/logo_color_transparent_background.png){width="105" height="17"} API ([access link](https://get.valueserp.com/try-it-free/)), data relative to Google searches have been gathered (see this first [document](https://github.com/lbajemon/glourb_serp)) for approximately 300 combinations of agglomerations and rivers. This document aims to calculate specificity scores for simple words (lemmas) as well as for n-grams.

We will use the mixr package (Vaudor, 2020).

```{r set_up}
library(mixr)
library(dplyr)
library(tidytext)
library(ggplot2)
library(ggpattern)
library(forcats)
```

##### 1. Analysis of the English data

```{r prepare_data}
df = read.csv("2_get_data/english/df_compile.csv")
```

##### a. Lemmas

```{r get_lemma_english, results = 'hide', warning = FALSE, message = FALSE}

## PREPARE TABLES OF WORDS TO REMOVE

# proper nouns (resulting from the 1st method)
lexen = get_lexicon("en")
proper_nouns = df %>% 
    # we consider the words starting with a capital letter
    mutate(word = str_extract_all(snippet, "[A-Z][a-z]*")) %>% 
    select(word) %>% 
    tidyr::unnest(cols = c(word)) %>% # get one row per word
    mutate(basis = str_to_lower(word)) %>% 
    group_by(word, basis)   %>% 
    summarise(n = n()) %>% # group by words
    # arrange(desc(n)) %>% 
    # see if these capitalized words appear (uncapitalized) in the lexicon
    left_join(lexen, by = c("basis" = "word")) %>% 
    # if not, then we can probably consider they are proper names
    filter(is.na(type)) %>% 
    select(word, n) %>% 
    mutate(word = str_to_lower(word)) %>% 
    na.omit()

# months and days
months = data.frame(word = c("jan","jeb","mar","apr","may","jun","jul","aug","sep","oct","nov","dec", "january","february","march","april","june","july","august","september","october","november","december", "monday","tuesday","wednesday","thursday","friday","saturday","sunday"))

# solitary letters
solitary = data.frame(word = c('a','z','e','r','t','y','u','i','o','p','q','s','d','f','g','h','j','k','l','m','w','x','c','v','b','n'))

# name of the countries
country_names = data_city_river[,5] %>% #keep only the country names
  unique() %>%
  strsplit(split = " ") %>% # split the name of the country if necessary (e.g. "Republic of the Congo" gives "Republic" "of "the" "Congo")
  unlist() %>% 
  as_tibble() %>% # convert to tibble
  set_names("word") %>% 
  mutate(word = str_replace_all(word, "\\(\\)", "")) %>% # remove special char
  mutate(word = str_replace_all(word, ",", "")) %>% 
  mutate(word = str_replace_all(word, "\\(", "")) %>% 
  mutate(word = str_replace_all(word, "\\)", "")) %>% 
  mutate(word = str_replace_all(word, "[.]", "")) %>% 
  mutate(word = tolower(word))

# name of the cities
city_names = data_city_river[,4] %>% 
  unique() %>% 
  strsplit(" |\\-") %>% 
  unlist() %>% 
  as_tibble() %>% 
  set_names("word") %>% 
  mutate(word = str_replace_all(word, "\\(\\)", "")) %>% 
  mutate(word = str_replace_all(word, ",", "")) %>% 
  mutate(word = str_replace_all(word, "\\(", "")) %>% 
  mutate(word = str_replace_all(word, "\\)", "")) %>% 
  mutate(word = str_replace_all(word, "[.]", "")) %>% 
  mutate(word = tolower(word))

## GET TOKENS FROM SNIPPETS
snippet_tokens_english = data.frame(df$snippet) %>% 
  mutate(doc = paste0(df$cityname, df$position)) %>%
  unnest_tokens(word, df.snippet, to_lower = TRUE)

## CLEAN THE TOKENS 
# using the previous tables
snippet_clean_english = snippet_tokens_english %>% 
  anti_join(stop_words) %>% 
  anti_join(proper_nouns) %>% 
  anti_join(months) %>%
  anti_join(country_names) %>% 
  anti_join(city_names) %>% 
  mutate(word = str_remove_all(word, '[[:digit:]]')) %>%
  anti_join(solitary) %>% 
  mutate(word = str_remove_all(word, '[[:punct:]]')) %>% 
  na.omit() %>% 
  subset(word != "") # remove empty rows

# for each word, get cityname and snippet position
snippet_clean_english$city = gsub("\\d", "", snippet_clean_english$doc)
snippet_clean_english$position = gsub("\\D", "", snippet_clean_english$doc)
```

##### b. Specificity scores calculation

```{r lemma_english_specificity}
spec_english = tidy_specificities(snippet_clean_english,
                                  cat1 = word,
                                  cat2 = city, 
                                  min_spec = 2)

plot1 = plot_specificities(spec_english,
                           cat1 = word,
                           cat2 = city)
plot1
```

Plots

```{r}
library(ggplot2)
library(forcats)

# AHMEDABAD
data_ahmedabad = subset(snippet_clean_english, snippet_clean_english$city == "Ahmedabad")
data = data_ahmedabad %>% 
  count(word) %>% 
  subset(n > 2)
rivername = "Ahmedabad"
cityname = "Sabarmati river"

# KHARTOUM
data_khartoum = subset(snippet_clean_english, snippet_clean_english$city == "Al-Khartum (Khartoum)")
data = data_khartoum %>% 
  count(word) %>% 
  subset(n > 1)
rivername = "Khartoum"
cityname = "Nile river"

# BAMAKO
data_bamako = subset(snippet_clean_english, snippet_clean_english$city == "Bamako")
data = data_bamako %>% 
  count(word) %>% 
  subset(n > 2)
rivername = "Bamako"
cityname = "Niger river"

# DENVER
data_denver = subset(snippet_clean_english, snippet_clean_english$city == "Denver-Aurora")
data = data_denver %>% 
  count(word) %>% 
  subset(n > 3) %>% 
  subset(word != "south") %>% 
  subset(word != "platte") %>% 
  subset(word != "river")
rivername = "South Platte river"
cityname = "Denver"

  myplot = data %>% # our data
    mutate(word = fct_reorder(word, n)) %>% # rearrange in decreasing order
    ggplot(mapping = aes(x = word,
                         y = n), color = "#fb9a99") + 
    geom_col(fill = "#fb9a99") +
    coord_flip() + # flip x and y coordinates 
    labs(title = paste("Requête : « ", rivername, " AND ", cityname, " »", sep = ""),
         pattern = "",
         x = "lemme",
         y = "fréquence"
    ) + 
    theme_classic()
  
  myplot # display the plot
  
  
# AGRA
data_ros = subset(snippet_clean_english, snippet_clean_english$city == "Rosario")
data = data_ros %>% 
  count(word) %>% 
  subset(n > 3) %>% 
  subset(word != "rosario") %>% 
  subset(word != "river") %>% 
  subset(word != "paraná") 
rivername = "Paraná river"
cityname = "Rosario"

  myplot = data %>% # our data
    mutate(word = fct_reorder(word, n)) %>% # rearrange in decreasing order
    ggplot(mapping = aes(x = word,
                         y = n)) + 
    geom_col(fill = "#e7298a") +
    coord_flip() + # flip x and y coordinates 
    labs(title = paste("Requête : « ", rivername, " AND ", cityname, " »", sep = ""),
         pattern = "",
         x = "lemme",
         y = "fréquence"
    ) + 
    theme_classic()
  
  myplot # display the plot
```
